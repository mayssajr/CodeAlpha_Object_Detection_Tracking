{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "from moviepy.editor import VideoFileClip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input video path\n",
    "input_video_path = '/content/CodeAlpha_Object_Detection_Tracking/input_video.mp4'  \n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Check if the video was opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Unable to open video '{input_video_path}'\")\n",
    "    exit()\n",
    "\n",
    "# Output video path\n",
    "output_dir = '/content/CodeAlpha_Object_Detection_Tracking/runs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_video_path = os.path.join(output_dir, 'video.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read frames and perform detection and tracking\n",
    "frame_count = 0\n",
    "max_frames = 300  # Limit frames to avoid infinite loop\n",
    "\n",
    "while frame_count < max_frames:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect objects with YOLOv8\n",
    "    results = model(frame)\n",
    "\n",
    "    # Draw results on the frame\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n",
    "        scores = result.boxes.conf.cpu().numpy()  # Confidence scores\n",
    "        classes = result.boxes.cls.cpu().numpy()  # Predicted classes\n",
    "\n",
    "        for box, score, cls in zip(boxes, scores, classes):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            class_id = int(cls)\n",
    "            label = f'{class_labels[class_id]} {score:.2f}'\n",
    "\n",
    "            # Draw the detection box on the image\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Increase font size for the label text\n",
    "            font_scale = 1.0\n",
    "            font_thickness = 2\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            text_size = cv2.getTextSize(label, font, font_scale, font_thickness)[0]\n",
    "            text_x = x1\n",
    "            text_y = y1 - 10\n",
    "\n",
    "            # Ensure text stays within image boundaries\n",
    "            if text_y - text_size[1] < 0:\n",
    "                text_y = y1 + 10 + text_size[1]\n",
    "\n",
    "            # Draw text background rectangle\n",
    "            cv2.rectangle(frame, (text_x, text_y - text_size[1]), (text_x + text_size[0], text_y + 2), (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "            # Draw the label text on the image\n",
    "            cv2.putText(frame, label, (text_x, text_y), font, font_scale, (0, 0, 0), font_thickness)\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Release the capture and close the output files\n",
    "cap.release()\n",
    "out.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la vidéo en gif\n",
    "clip = VideoFileClip(output_video_path)\n",
    "gif_path = os.path.join(output_dir, 'video.gif')\n",
    "clip.write_gif(gif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=gif_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Traitement terminé. Sortie enregistrée dans '{output_video_path}' et GIF créé: '{gif_path}'\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
